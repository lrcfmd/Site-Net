=== create_mp_gap_hdf5.py ===

--primitive generates a dataset of primitive unit cells
--cubic_supercell generates a dataset of supercells
-s --supercell_size allows the size of the supercells to be specified
-w --number_of_worker_processes allows the number of cpu threads used to be specified (default 1)

either --primitive or --cubic_supercell must be used

provide the size of the supercell (if applicable) with -s N where N is the maximum number of atoms

=== train.py ===

-c --config allows the path of the configuration file to be specified (default None)
-f --h5_file_name allows the path of the h5 dataset used for training to be specified (default None)
-l --load_checkpoints allows training to be resumed from the most recent checkpoint for a given config file (default 0)
-o --overwrite will force the generation of new features, followed by overwriting, instead of reading them from the h5 file (default False)
-d --debug will limit the model to loading the first 1000 samples (default False)
-u --unit_cell_limit will exclude unit cells larger than this size from training (default 100)
-w --number_of_worker_processes controls the maximum number of cpu threads that site-net will use (default 1)

=== predict.py ===

-c --config allows the path of the configuration file to be specified (default None)
-f --dataset allows the path of the h5 dataset used for training to be specified (default None)
-n --limit allows a smaller subset of the data to be used for the inference (default None)
-m --model_name allows the checkpoint path to be specified (default None)
-w --number_of_worker_processes allows the number of cpu threads to be specified (default 1)